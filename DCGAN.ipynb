{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,UpSampling2D,BatchNormalization,Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_function( ):\n",
    "    model = Sequential( )\n",
    "    model.add(Dense( units =1024 , activation=\"relu\" , input_dim=900) )\n",
    "    model.add(Dense(2048, activation='relu') )\n",
    "    #Dense layers in starting\n",
    "    model.add(Dense(224*8*8 , activation=\"relu\" ) )\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Reshape((8,8,224),input_shape=(224*8*8,)))\n",
    "    #Reshaping 1_D tensor in form of 3_D tensor\n",
    "    model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "    model.add(UpSampling2D(size=(2,2)))\n",
    "    model.add(Conv2D(32,(3,3),padding='valid',activation='relu'))\n",
    "    model.add(UpSampling2D(size=(2,2)))\n",
    "    model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "    model.add(UpSampling2D(size=(2,2)))\n",
    "    model.add(Conv2D(32,(3,3),padding='same',activation='relu'))\n",
    "    model.add(UpSampling2D(size=(2,2)))\n",
    "    model.add(Conv2D(16,(5,5),padding='same',activation='relu'))\n",
    "    model.add(UpSampling2D(size=(2,2)))\n",
    "    model.add(Conv2D(1,(7,7),padding='same',activation='sigmoid'))\n",
    "    #convolutional layers and max_pooling layers to make the final output of generator of size of image\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_function():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(16,(7,7),padding='same',activation='relu',input_shape=(224,224,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(32,(5,5),padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(224,(3,3),padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048,activation='relu'))\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator,discriminator):\n",
    "    model=Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable=False\n",
    "    model.add(discriminator)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading fingerprint images\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def take_input():\n",
    "\n",
    "    prefix=\"C:\\\\Users\\\\DELL1\\\\Desktop\\\\Gan\\\\DB1\\\\\"\n",
    "    imageNames=os.listdir(prefix)\n",
    "    images=[]\n",
    "    for imageName in imageNames :\n",
    "        image_path = prefix + imageName\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image,(224,224))\n",
    "        image = cv2.cvtColor( image , cv2.COLOR_RGB2GRAY)\n",
    "        image = image.reshape (224 , 224 , 1)\n",
    "        image = image.astype( 'float32' )/255\n",
    "        images.append( image )\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "def train(batch_size):\n",
    "    X_train = take_input()\n",
    "    discriminator=discriminator_function()\n",
    "    generator=generator_function()\n",
    "    discriminator_on_generator_model=generator_containing_discriminator(generator,discriminator)\n",
    "    d_optim=Adam(lr=0.00001,beta_1=.9,beta_2=.999)\n",
    "    g_optim=Adam(lr=.0001,beta_1=.9,beta_2=.999)\n",
    "    generator.compile(loss='binary_crossentropy',optimizer=g_optim)\n",
    "    discriminator_on_generator_model.compile(loss='binary_crossentropy',optimizer=g_optim)\n",
    "    discriminator.trainable=True\n",
    "    discriminator.compile(loss='binary_crossentropy',optimizer=d_optim)\n",
    "    \n",
    "    noise=np.zeros((batch_size,900))\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch is\",epoch)\n",
    "        print(\"Number of Batches\", int(len(X_train)/batch_size))\n",
    "        for index in range(int(len(X_train)/batch_size)):\n",
    "            for i in range(batch_size):\n",
    "                noise[i,:]=np.random.uniform(0,1,900)\n",
    "            noise=noise.reshape(batch_size,900)\n",
    "            image_batch=X_train[index*batch_size:(index+1)*batch_size]\n",
    "            generated_images=generator.predict(noise,verbose=0)\n",
    "            #generated images will contain the images generated by generator, no. of images will be batch_size\n",
    "            if index%20==0:\n",
    "                #saving the image after every 20 batches\n",
    "                for i in range(batch_size):\n",
    "                    image=generated_images[i]*255\n",
    "                    image= Image.fromarray(image.reshape(224,224).astype('uint8')).convert('RGB')\n",
    "                    image.save(\"C:\\\\Users\\\\DELL1\\\\Desktop\\\\Gan\\\\\"+str( epoch )+\" \"+str( index )+\".png\")\n",
    "            X=np.concatenate((np.asarray(image_batch),generated_images))\n",
    "            #Taking real & gen.images in same array\n",
    "            y=[1]*batch_size + [0]*batch_size\n",
    "            #Labelling images according to ther class\n",
    "            d_loss=discriminator.train_on_batch(X,y)\n",
    "            #This step will update the weights of discriminator model and output the loss after update\n",
    "            print(\"batch %d d_loss : %f\" %(index,d_loss))\n",
    "            for i in range(batch_size):\n",
    "                noise[i,:]=np.random.uniform(0,1,900)\n",
    "            noise=noise.reshape(batch_size,900)\n",
    "            #generating noise of batch_size\n",
    "            discriminator.trainable=False\n",
    "            noise1=np.random.uniform(0,1,900)\n",
    "            noise1=noise1.reshape(1,900)\n",
    "            g_loss= discriminator_on_generator_model.train_on_batch(noise,[1]*batch_size)\n",
    "            #The combined model has given the noise as input and output of one since we want to generate real images\n",
    "            ## This step will update the weights of generator model and output the loss after update\n",
    "            discriminator.trainable=True\n",
    "            print(\"batch %d g_loss : %f\" %(index,g_loss))\n",
    "            #Saving both the models after every batch\n",
    "        generator.save_weights(\"C:\\\\Users\\\\DELL1\\\\Desktop\\\\Gan\\\\gen\"+str(epoch)+'.h5',True)\n",
    "        discriminator.save_weights(\"C:\\\\Users\\\\DELL1\\\\Desktop\\\\Gan\\\\dis\"+str(epoch)+'.h5',True)\n",
    "            \n",
    "                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(batch_size):\n",
    "    generator=generator_function()\n",
    "    generator.compile(loss='binary_crossentropy',optimizer='SGD')\n",
    "    generator.load_weights(\"C:\\\\Users\\\\DELL1\\\\Desktop\\\\Gan\\\\gen1.h5\")\n",
    "    noise=np.zeros((batch_size,900))\n",
    "    for i in range(batch_size):\n",
    "        noise[i,:]=np.random.uniform(0,1,900)\n",
    "    generated_images= generator.predict(noise,verbose=1)\n",
    "    for i in range(batch_size):\n",
    "        image=generated_images[i]*255\n",
    "        image=Image.fromarray(image.reshape(224,224).astype('uint8')).convert('RGB')\n",
    "        image.save(\"C:\\\\Users\\\\DELL1\\\\Desktop\\\\Gan\\\\Generated_images\\\\\"+str(i)+\".png\")\n",
    "        #saving the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of Batches 5\n",
      "batch 0 d_loss : 0.689784\n",
      "batch 0 g_loss : 0.665754\n",
      "batch 1 d_loss : 0.679770\n",
      "batch 1 g_loss : 0.642119\n",
      "batch 2 d_loss : 0.669400\n",
      "batch 2 g_loss : 0.619376\n",
      "batch 3 d_loss : 0.663857\n",
      "batch 3 g_loss : 0.599498\n",
      "batch 4 d_loss : 0.662420\n",
      "batch 4 g_loss : 0.581712\n",
      "Epoch is 1\n",
      "Number of Batches 5\n",
      "batch 0 d_loss : 0.649675\n",
      "batch 0 g_loss : 0.569060\n",
      "batch 1 d_loss : 0.651766\n",
      "batch 1 g_loss : 0.559485\n",
      "batch 2 d_loss : 0.642660\n",
      "batch 2 g_loss : 0.552598\n",
      "batch 3 d_loss : 0.642102\n",
      "batch 3 g_loss : 0.547524\n",
      "batch 4 d_loss : 0.646556\n",
      "batch 4 g_loss : 0.543223\n"
     ]
    }
   ],
   "source": [
    "#As I am using my laptop with just 8gb ram, I gave epochs=2. Normally, it should be at least equal to 100 to produce accurate results. \n",
    "\n",
    "train=train(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 13s 201ms/step\n"
     ]
    }
   ],
   "source": [
    "gen=generate(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 224, 224, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator=generator_function()\n",
    "generator.output_shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
